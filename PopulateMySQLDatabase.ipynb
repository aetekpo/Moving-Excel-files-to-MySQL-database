{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Date: 1/05/2025\n",
    "Author: Asserewou Etekpo\n",
    "Tpoic: Populate MySQL Database with data from an csv file with Multiple sheets using Python\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Step 1: Read the Excel file into pandas DataFrames\n",
    "file_path = 'C:/Users/honor/OneDrive/Documents/CreditCardProject/data/splitsubfraudtest.xlsx'\n",
    "\n",
    "\n",
    "excel_data = pd.read_excel(file_path, sheet_name=None)  # Read all sheets\n",
    "\n",
    "# Step 2: Assign each sheet to a DataFrame\n",
    "\n",
    "df_Location = excel_data['sheet_Location']\n",
    "\n",
    "df_Cardholder = excel_data['sheet_Cardholder']\n",
    "\n",
    "df_Merchant = excel_data['sheet_Merchant']\n",
    "\n",
    "df_Transaction = excel_data['sheet_Transaction']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check for duplicates on the PK (zip) in df_Location dataframe\n",
    "\n",
    "df_Location.duplicated() # We have some duplicates in the dataframe df_Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop duplicates in df_Location based on the 'zip' column\n",
    "\n",
    "df_Location_unique = df_Location.drop_duplicates(subset=\"zip\", keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the 'zip' column\n",
    "duplicate_rows = df_Location_unique[df_Location_unique.duplicated(subset=\"zip\", keep=False)]\n",
    "print(\"Duplicate rows:\")\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check for duplicates on the PK (cc_num) in df_Cardholder dataframe\n",
    "\n",
    "df_Cardholder.duplicated() # We have some duplicates in the dataframe df_Cardholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop duplicates in df_Cardholder based on the 'cc_num' column\n",
    "\n",
    "df_Cardholder_unique = df_Cardholder.drop_duplicates(subset=\"cc_num\", keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the 'cc_num' column\n",
    "duplicate_rows1 = df_Cardholder_unique[df_Cardholder_unique.duplicated(subset=\"cc_num\", keep=False)]\n",
    "print(\"Duplicate rows:\")\n",
    "print(duplicate_rows1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cardholder_unique.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop duplicates in df_Merchant based on the 'merchant' column\n",
    "\n",
    "df_Merchant_unique = df_Merchant.drop_duplicates(subset=\"merchant\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the 'merchant' column\n",
    "duplicate_rows2 = df_Merchant_unique[df_Merchant_unique.duplicated(subset=\"merchant\", keep=False)]\n",
    "print(\"Duplicate rows:\")\n",
    "print(duplicate_rows2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Merchant_unique.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop duplicates in df_Transaction based on the 'trans_num' column\n",
    "\n",
    "df_Transaction_unique = df_Transaction.drop_duplicates(subset=\"trans_num\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the 'trans_num' column\n",
    "duplicate_rows3 = df_Transaction_unique[df_Transaction_unique.duplicated(subset=\"trans_num\", keep=False)]\n",
    "print(\"Duplicate rows:\")\n",
    "print(duplicate_rows3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Transaction_unique.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates have been removed on all Primary Key's in all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check for the format of the column dob.\n",
    "\n",
    "df_Cardholder_unique[\"dob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the 'dob' column to the correct format (YYYY-MM-DD) in df_Cardholder\n",
    "\n",
    "df_Cardholder_unique['dob'] = pd.to_datetime(df_Cardholder_unique['dob'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column to datetime type (if not already)\n",
    "\n",
    "df_Transaction_unique['trans_date_trans_time'] = pd.to_datetime(df_Transaction_unique['trans_date_trans_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string to a Python datetime object\n",
    "#df_Transaction_unique['trans_date_trans_time'] = datetime.strptime('trans_date_trans_time', '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Transaction_unique['trans_date_trans_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert datetime to string in the desired format (YYYY-MM-DD HH:MM:SS)\n",
    "\n",
    "df_Transaction_unique['trans_date_trans_time'] = df_Transaction_unique['trans_date_trans_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Transaction_unique['trans_date_trans_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load the data into the MySQL database\n",
    "\n",
    "# Establish a connection to MySQL database\n",
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        database='creditcard_db',\n",
    "        user='root',\n",
    "        password='********'\n",
    "    )\n",
    "\n",
    "    if connection.is_connected():\n",
    "        print('Connected to MySQL database')\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Step 3: Insert data into each table\n",
    "        # Insert data for Location table\n",
    "        for index, row in df_Location_unique.iterrows():\n",
    "            # Convert row to tuple\n",
    "            cursor.execute(\"INSERT INTO Location (zip, city, state, latitude, longitude, city_pop) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                           tuple(row))  # Convert row to tuple\n",
    "\n",
    "        # Insert data for Cardholder table\n",
    "        for index, row in df_Cardholder_unique.iterrows():\n",
    "            cursor.execute(\"INSERT INTO Cardholder (cc_num, first, last, gender, street, city, state, zip, job, dob) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "                           tuple(row))  # Convert row to tuple\n",
    "\n",
    "        # Insert data for Merchant table\n",
    "        for index, row in df_Merchant_unique.iterrows():\n",
    "            cursor.execute(\"INSERT INTO Merchant (merchant,category, merch_lat, merch_long) VALUES (%s, %s, %s, %s)\",\n",
    "                           tuple(row))  # Convert row to tuple\n",
    "\n",
    "        # Insert data for Transaction table\n",
    "        for index, row in df_Transaction_unique.iterrows():\n",
    "            cursor.execute(\"INSERT INTO Transaction (trans_num, cc_num, trans_date_trans_time, amt, is_fraud, merchant) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                           tuple(row))  # Convert row to tuple\n",
    "\n",
    "\n",
    "        # Commit the changes to the database\n",
    "        connection.commit()\n",
    "        print(\"Data inserted successfully\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"Connection closed.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
